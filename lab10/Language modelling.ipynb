{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Language modelling\n",
    "\n",
    "The exercise shows how a language model may be used to solve word-prediction tasks and used to generate text.\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Read the documentation of [Language modelling in the Transformers](https://huggingface.co/transformers/task_summary.html#language-modeling) library.\n",
    ">Done\n",
    "2. Download three [Polish models](https://huggingface.co/models?filter=pl) from the Huggingface repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micha/anaconda3/lib/python3.7/site-packages/transformers/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at henryk/bert-base-multilingual-cased-finetuned-polish-squad2 were not used when initializing BertForMaskedLM: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at henryk/bert-base-multilingual-cased-finetuned-polish-squad2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForMaskedLM, AutoModelWithLMHead\n",
    "import torch\n",
    "\n",
    "def import_model_tokenizer(name):\n",
    "    model: AutoModel  = AutoModelWithLMHead.from_pretrained(name)\n",
    "    tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(name)\n",
    "    config: AutoConfig = AutoConfig.from_pretrained(name)\n",
    "    return model, tokenizer\n",
    "\n",
    "names = [\"allegro/herbert-base-cased\",\n",
    "         \"dkleczek/bert-base-polish-cased-v1\",\n",
    "        # \"henryk/bert-base-multilingual-cased-finetuned-polish-squad1\"\n",
    "        \"henryk/bert-base-multilingual-cased-finetuned-polish-squad2\"\n",
    "         # \"DeepPavlov/bert-base-bg-cs-pl-ru-cased\"\n",
    "         ]\n",
    "\n",
    "\n",
    "models_tokenizers = []\n",
    "for name in names:\n",
    "    model, tokenizer = import_model_tokenizer(name)\n",
    "    models_tokenizers.append((model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Produce the predictions for the following sentences (use each model and check 5 predictions):\n",
    "   1. (M) Warszawa to największe `[MASK]`.\n",
    "   1. (D) Te zabawki należą do `[MASK]`.\n",
    "   1. (C) Policjant przygląda się `[MASK]`.\n",
    "   1. (B) Na środku skrzyżowania widać `[MASK]`.\n",
    "   1. (N) Właściciel samochodu widział złodzieja z `[MASK]`.\n",
    "   1. (Ms) Prezydent z premierem rozmawiali wczoraj o `[MASK]`.\n",
    "   1. (W) Witaj drogi `[MASK]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def predict(sequence, model, tokenizer):\n",
    "  sequence = re.sub(r\"\\?\",tokenizer.mask_token, sequence)\n",
    "  input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "  mask_token_index = torch.where(input == tokenizer.mask_token_id)[1][0].item()\n",
    "  token_logits = model(input)[0]\n",
    "  mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "  top_5_tokens = torch.topk(mask_token_logits, 5)[-1]\n",
    "  for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))\n",
    "\n",
    "def predict_for_examples(examples):\n",
    "    for example in examples:\n",
    "        for model_tokenizer in models_tokenizers:\n",
    "            print(model_tokenizer[0].name_or_path)\n",
    "            predict(example, model_tokenizer[0], model_tokenizer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allegro/herbert-base-cased\n",
      "Warszawa to największe miasto.\n",
      "Warszawa to największe lotnisko.\n",
      "Warszawa to największe centrum.\n",
      "Warszawa to największe miasta.\n",
      "Warszawa to największe atrakcje.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Warszawa to największe miasto.\n",
      "Warszawa to największe województwo.\n",
      "Warszawa to największe lotnisko.\n",
      "Warszawa to największe miasteczko.\n",
      "Warszawa to największe państwo.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Warszawa to największe њ.\n",
      "Warszawa to największe Kantoni.\n",
      "Warszawa to największe hrvatskog.\n",
      "Warszawa to największe ##czeństwa.\n",
      "Warszawa to największe rež.\n",
      "allegro/herbert-base-cased\n",
      "Te zabawki należą do rodziny.\n",
      "Te zabawki należą do nas.\n",
      "Te zabawki należą do nich.\n",
      "Te zabawki należą do najlepszych.\n",
      "Te zabawki należą do ..\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Te zabawki należą do ciebie.\n",
      "Te zabawki należą do mnie.\n",
      "Te zabawki należą do nas.\n",
      "Te zabawki należą do pana.\n",
      "Te zabawki należą do niego.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Te zabawki należą do ##lezh.\n",
      "Te zabawki należą do blisko.\n",
      "Te zabawki należą do ##sium.\n",
      "Te zabawki należą do rež.\n",
      "Te zabawki należą do ##czeństwa.\n",
      "allegro/herbert-base-cased\n",
      "Policjant przygląda się mężczyźnie.\n",
      "Policjant przygląda się kobiecie.\n",
      "Policjant przygląda się mu.\n",
      "Policjant przygląda się dziewczynie.\n",
      "Policjant przygląda się sprawie.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Policjant przygląda się temu.\n",
      "Policjant przygląda się sprawie.\n",
      "Policjant przygląda się im.\n",
      "Policjant przygląda się wszystkiemu.\n",
      "Policjant przygląda się panu.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Policjant przygląda się ##czeństwa.\n",
      "Policjant przygląda się hrvatskog.\n",
      "Policjant przygląda się rež.\n",
      "Policjant przygląda się ##lezh.\n",
      "Policjant przygląda się Kantoni.\n",
      "allegro/herbert-base-cased\n",
      "Na środku skrzyżowania widać rondo.\n",
      "Na środku skrzyżowania widać samochody.\n",
      "Na środku skrzyżowania widać radiowóz.\n",
      "Na środku skrzyżowania widać samochód.\n",
      "Na środku skrzyżowania widać wiadukt.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Na środku skrzyżowania widać rzekę.\n",
      "Na środku skrzyżowania widać ulicę.\n",
      "Na środku skrzyżowania widać drzewa.\n",
      "Na środku skrzyżowania widać drogę.\n",
      "Na środku skrzyżowania widać las.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Na środku skrzyżowania widać rež.\n",
      "Na środku skrzyżowania widać ##lezh.\n",
      "Na środku skrzyżowania widać ##czeństwa.\n",
      "Na środku skrzyżowania widać Kantoni.\n",
      "Na środku skrzyżowania widać blisko.\n",
      "allegro/herbert-base-cased\n",
      "Właściciel samochodu widział złodzieja z samochodu.\n",
      "Właściciel samochodu widział złodzieja z włamaniem.\n",
      "Właściciel samochodu widział złodzieja z auta.\n",
      "Właściciel samochodu widział złodzieja z kierowcą.\n",
      "Właściciel samochodu widział złodzieja z parkingu.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Właściciel samochodu widział złodzieja z bronią.\n",
      "Właściciel samochodu widział złodzieja z tyłu.\n",
      "Właściciel samochodu widział złodzieja z ulicy.\n",
      "Właściciel samochodu widział złodzieja z bliska.\n",
      "Właściciel samochodu widział złodzieja z zewnątrz.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Właściciel samochodu widział złodzieja z ##czeństwa.\n",
      "Właściciel samochodu widział złodzieja z blisko.\n",
      "Właściciel samochodu widział złodzieja z rež.\n",
      "Właściciel samochodu widział złodzieja z ##lezh.\n",
      "Właściciel samochodu widział złodzieja z Kantoni.\n",
      "allegro/herbert-base-cased\n",
      "Prezydent z premierem rozmawiali wczoraj o przyszłości.\n",
      "Prezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "Prezydent z premierem rozmawiali wczoraj o bezpieczeństwie.\n",
      "Prezydent z premierem rozmawiali wczoraj o polityce.\n",
      "Prezydent z premierem rozmawiali wczoraj o Warszawie.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Prezydent z premierem rozmawiali wczoraj o tym.\n",
      "Prezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "Prezydent z premierem rozmawiali wczoraj o budżecie.\n",
      "Prezydent z premierem rozmawiali wczoraj o ASF.\n",
      "Prezydent z premierem rozmawiali wczoraj o ustawie.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Prezydent z premierem rozmawiali wczoraj o ##czeństwa.\n",
      "Prezydent z premierem rozmawiali wczoraj o rež.\n",
      "Prezydent z premierem rozmawiali wczoraj o blisko.\n",
      "Prezydent z premierem rozmawiali wczoraj o ##lezh.\n",
      "Prezydent z premierem rozmawiali wczoraj o мелхан.\n",
      "allegro/herbert-base-cased\n",
      "Witaj, drogi Panie.\n",
      "Witaj, drogi człowieku.\n",
      "Witaj, drogi panie.\n",
      "Witaj, drogi Boże.\n",
      "Witaj, drogi Łukasz.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Witaj, drogi chłopcze.\n",
      "Witaj, drogi przyjacielu.\n",
      "Witaj, drogi bracie.\n",
      "Witaj, drogi panie.\n",
      "Witaj, drogi kolego.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Witaj, drogi 嘩.\n",
      "Witaj, drogi ##siones.\n",
      "Witaj, drogi ##ュージック.\n",
      "Witaj, drogi ##utore.\n",
      "Witaj, drogi ##нство.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "            \"Warszawa to największe ?.\",\n",
    "            \"Te zabawki należą do ?.\",\n",
    "            \"Policjant przygląda się ?.\",\n",
    "            \"Na środku skrzyżowania widać ?.\",\n",
    "            \"Właściciel samochodu widział złodzieja z ?.\",\n",
    "            \"Prezydent z premierem rozmawiali wczoraj o ?.\",\n",
    "            \"Witaj, drogi ?.\"\n",
    "]\n",
    "\n",
    "predict_for_examples(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Check the model predictions for the following sentences (using each model):\n",
    "   1. Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie `[MASK]`.\n",
    "   1. Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie `[MASK]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allegro/herbert-base-cased\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zdziwił.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie poddał.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zastanawiał.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie przyznał.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zgodził.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie martwił.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie bał.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zabił.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##lució.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##んな.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##xecto.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##ュージック.\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie 嘩.\n",
      "allegro/herbert-base-cased\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie przyznała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie śmiała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zmieniła.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zgodziła.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zabiła.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie pojawiła.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##lució.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie 嘩.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##ュージック.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##んな.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##ycling.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "  \"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ?.\",\n",
    "  \"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ?.\"\n",
    "]\n",
    "\n",
    "predict_for_examples(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Check the model predictions for the following sentences:\n",
    "   1. `[MASK]` wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
    "   1. W wakacje odwiedziłem `[MASK]`, który jest stolicą Islandii.\n",
    "   1. Informatyka na `[MASK]` należy do najlepszych kierunków w Polsce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allegro/herbert-base-cased\n",
      "Woda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Słońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Ziemia wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Następnie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Ciało wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Woda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Mięso wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Słońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Nie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Piwo wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "rež wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "hrvatskog wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "##lezh wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "Kantoni wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "##lució wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "allegro/herbert-base-cased\n",
      "W wakacje odwiedziłem Kraków, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Oslo, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Londyn, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Gdańsk, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Toruń, który jest stolicą Islandii.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "W wakacje odwiedziłem kraj, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Cypr, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Meksyk, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Gibraltar, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Wellington, który jest stolicą Islandii.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "W wakacje odwiedziłem ##czeństwa, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem blisko, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem Kantoni, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem rež, który jest stolicą Islandii.\n",
      "W wakacje odwiedziłem мелхан, który jest stolicą Islandii.\n",
      "allegro/herbert-base-cased\n",
      "Informatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na AGH należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na UW należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na studiach należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na UMK należy do najlepszych kierunków w Polsce.\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Informatyka na wsi należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na świecie należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na żywo należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na odległość należy do najlepszych kierunków w Polsce.\n",
      "henryk/bert-base-multilingual-cased-finetuned-polish-squad2\n",
      "Informatyka na ##czeństwa należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na Kantoni należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na ##lució należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na ##sium należy do najlepszych kierunków w Polsce.\n",
      "Informatyka na ##ksesta należy do najlepszych kierunków w Polsce.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "  \"? wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\",\n",
    "  \"W wakacje odwiedziłem ?, który jest stolicą Islandii.\",\n",
    "  \"Informatyka na ? należy do najlepszych kierunków w Polsce.\",\n",
    "]\n",
    "\n",
    "predict_for_examples(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Answer the following questions:\n",
    "   1. Which of the models produced the best results?\n",
    "   > Najlepsze rezultaty osiągnęły modele allegro/herbert-base-cased i dkleczek/bert-base-polish-cased-v1.\n",
    "\n",
    "   1. Was any of the models able to capture Polish grammar?\n",
    "   > Tak, modele allegro/herbert-base-cased oraz dkleczek/bert-base-polish-cased-v1 dobrze radzą sobie z polską gramatyką.\n",
    "   > W zadaniu 3 te model w większości przypadków zastosowały odpowiednią rekcję.\n",
    "\n",
    "   1. Was any of the models able to capture long-distant relationships between the words?\n",
    "   > Tak, allegro/herbert-base-cased oraz dkleczek/bert-base-polish-cased-v1 uchwyciły długodystansową relację.\n",
    "   > W zadaniu 4 te modele bezbłędnie wybrały właściwy rodzaj.\n",
    "\n",
    "   1. Was any of the models able to capture world knowledge?\n",
    "   > Modele allegro/herbert-base-cased i dkleczek/bert-base-polish-cased-v1 poradziły sobie dobrze z \"testem wrzącej wody\".\n",
    "   > Niestety żaden z modeli nie potrafił właściwie wskazać stolicy Islandii - Rejkiawiku. Model allegro proponował miasta, jako jedyny dla wszystkich w top 5, jako stolicę.\n",
    "   > Na podstawie tych wyników można powiedzieć, że modele uchwyciły (chociaż częściowo) wiedzę ogólną.\n",
    "\n",
    "   1. What are the most striking errors made by the models?\n",
    "   > Trzeci z wybranych modeli henryk/bert-base-multilingual-cased-finetuned-polish-squad2 (ale także modele henryk/bert-base-multilingual-cased-finetuned-polish-squad1 i DeepPavlov/bert-base-bg-cs-pl-ru-cased) prawdopodobnie ze względu na swoją wielojęzyczność dawały bardzo kiepskie wyniki.\n",
    "   > Moją uwagę wśród wyników z dwóch najlepszych modeli zwróciły:\n",
    "   > \"to bym się nie zabił/zabiła\"\n",
    "   > \"widział złodzieja z włamaniem\"\n",
    "   > \"Warszawa to największe miasteczko\"\n",
    "\n",
    "## Hints\n",
    "\n",
    "1. Language modelling (LM) is a task concentrated on computing the probability distribution of words given a sequence of\n",
    "   preceding words.\n",
    "2. In the past the most popular LM were based on n-gram counting. The distribution of probability of the next word was\n",
    "   approximated by the relative frequency of the last n-words, preceding this word. Usually n=3, since larger values\n",
    "   resulted in extremely large datasets.\n",
    "3. Many algorithms were devised to improve that probability estimates for infrequent words. Among them Kneser-Ney was\n",
    "   the most popular.\n",
    "4. SRI LM is the most popular toolkit for creating traditional language models.\n",
    "5. At present recurrent neural networks, attention networks and transformers are the most popular neural-network\n",
    "   architectures for creating LMs.\n",
    "6. The largest LM currently is GPT-3 described in (mind the number of authors!) *Language Models are Few-Shot Learners*\n",
    "   Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav\n",
    "   Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon\n",
    "   Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler,\n",
    "   Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\n",
    "   Sutskever, Dario Amodei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}