{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Text classification\n",
    "\n",
    "The task concentrates on content-based text classification.\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Get acquainted with the data of the [Polish Cyberbullying detection dataset](http://2019.poleval.pl/index.php/tasks/task6).\n",
    "   Pay special attention to the distribution of the positive and negative examples in the first task as well as\n",
    "   distribution of the classes in the second task.\n",
    "2. Train the following classifiers on the training sets (for the task 1 and the task 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "   i. Bayesian classifier with TF * IDF weighting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "   ii. Fasttext text classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext task1:\n",
      "Precision = 68.42%\n",
      "\n",
      "Recall = 9.70%\n",
      "\n",
      "Balanced F-score = 16.99%\n",
      "\n",
      "Accuracy = 87.30%\n",
      "\n",
      "Fasttext task2:\n",
      "Micro-Average F-score = 86.60%\n",
      "\n",
      "Macro-Average Precision = 0.622534269475092%\n",
      "\n",
      "Macro-Average Recall = 0.336006525838507%\n",
      "\n",
      "Macro-Average F-score = 43.64%\n",
      "\n",
      "precision0 is 0.867602808425276\n",
      "\n",
      "recall0 is 0.998845265588915\n",
      "\n",
      "precision1 is 0\n",
      "\n",
      "recall1 is 0\n",
      "\n",
      "precision2 is 1\n",
      "\n",
      "recall2 is 0.00917431192660551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def read_file_as_list(filename, directory):\n",
    "    li = []\n",
    "    with open(os.path.join(directory + filename), 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.replace('\\n', '')\n",
    "            li.append(line)\n",
    "    return li\n",
    "\n",
    "def combine_tags_and_texts(directory):\n",
    "    tags = read_file_as_list('training_set_clean_only_tags.txt', directory)\n",
    "    text = read_file_as_list('training_set_clean_only_text.txt', directory)\n",
    "\n",
    "    with open(os.path.join(directory + 'all.txt'), 'w') as file:\n",
    "        for i in range(len(tags)):\n",
    "            file.write('__label__'+tags[i]+' '+ text[i]+'\\n')\n",
    "\n",
    "def fasttext_train_predict(directory):\n",
    "    combine_tags_and_texts(directory)\n",
    "    import fasttext\n",
    "    test_data = read_file_as_list('test_set_clean_only_text.txt', directory)\n",
    "    text_data = test_data[:10]\n",
    "    model = fasttext.train_supervised(input=directory+'all.txt')\n",
    "    with open(os.path.join(directory + 'FastText_results.txt'), 'w') as file:\n",
    "        for t in test_data:\n",
    "            # print(t)\n",
    "            result = model.predict(t)[0][0].replace('__label__', '')\n",
    "            # print(result)\n",
    "            file.writelines(result+'\\n')\n",
    "\n",
    "def evaluate(directory, evaluator):\n",
    "    os.system(\"perl \"+directory+evaluator+\" \"+directory+\"FastText_results.txt > \"+directory+\"FastText_output.txt\")\n",
    "    file = open(directory+'FastText_output.txt')\n",
    "    for line in file:\n",
    "        print(line)\n",
    "\n",
    "print('Fasttext task1:')\n",
    "directory = 'task_6-1/'\n",
    "fasttext_train_predict(directory)\n",
    "evaluator = 'evaluate1.pl'\n",
    "evaluate(directory, evaluator)\n",
    "\n",
    "print('Fasttext task2:')\n",
    "directory = 'task_6-2/'\n",
    "fasttext_train_predict(directory)\n",
    "evaluator = 'evaluate2.pl'\n",
    "evaluate(directory, evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "   iii. Transformer classifier (take into account that a number of experiments should be performed for this model)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Compare the results of classification on the test set. Select the appropriate measuers (form accuracy, F1,\n",
    "   macro/micro F1, MCC) to compare the results.\n",
    "\n",
    "\n",
    "4. Select 1 TP, 1 TN, 1 FP and 1 FN from your predictions (for the best classifier) and compare the decisions of each\n",
    "   classifier on these examples using [SHAP](https://github.com/slundberg/shap).\n",
    "\n",
    "5. Answer the following questions:\n",
    "   1. Which of the classifiers works the best for the task 1 and the task 2.\n",
    "   1. Did you achieve results comparable with the results of [PolEval Task](http://2019.poleval.pl/index.php/results/)?\n",
    "   1. Did you achieve results comparabie with the [Klej leaderboard](https://klejbenchmark.com/leaderboard/)?\n",
    "   1. Describe strengths and weaknesses of each of the compared algorithms.\n",
    "   1. Do you think comparison of raw performance values on a single task is enough to assess the value of a given\n",
    "      algorithm/model?\n",
    "   1. Did SHAP show that the models use valuable featurs/words when performing their decision?\n",
    "\n",
    "## Hints\n",
    "\n",
    "1. You can use [Google colab](https://colab.research.google.com/notebooks/intro.ipynb) to perform experiments which\n",
    "   require access to GPU or TPU.\n",
    "1. [Fasttext](https://fasttext.cc/docs/en/supervised-tutorial.html) is a popular basline classifier. Don't report the Precision/Recall/F1 provided by\n",
    "   Fasttext since they might be [wrong](https://github.com/facebookresearch/fastText/issues/261).\n",
    "1. [Huggingsface Transformers](https://github.com/huggingface/transformers) library is a popular library for performing NLP tasks base on the transformer\n",
    "   architecture.\n",
    "1. [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) by Jurafsky and Martin\n",
    "   has a [chapter](https://web.stanford.edu/~jurafsky/slp3/4.pdf) devoted to the problem of classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}